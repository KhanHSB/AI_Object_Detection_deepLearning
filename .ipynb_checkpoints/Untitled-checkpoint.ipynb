{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "import cv2\n",
    "\n",
    "# from PIL import Image, ImageDraw, ImageFont\n",
    "import PIL as pil\n",
    "\n",
    "\"\"\"\n",
    "https://github.com/gbusr/YAD2K provides the base work for implementation of YOLO v2 in Keras and Tensorflow\n",
    "yad2k.py converts the YOLO's Darknet weights to Keras readable format\n",
    "\"\"\"\n",
    "from yad2k.models.keras_yolo import yolo_eval, yolo_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_data/yolo.h5'\n",
    "anchors_path = 'model_data/yolo_anchors.txt'\n",
    "classes_path = 'model_data/coco_classes.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdulhakeem\\Anaconda3\\lib\\site-packages\\keras\\models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "sess = K.get_session()  # TODO: Remove dependence on Tensorflow session.\n",
    "\n",
    "with open(classes_path) as f:\n",
    "    class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "\n",
    "with open(anchors_path) as f:\n",
    "    anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    anchors = np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "yolo_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model is fully convolutional, assuming channel last order.\n",
    "model_image_size = yolo_model.layers[0].input_shape[1:3]\n",
    "is_fixed_size = model_image_size != (None, None)\n",
    "\n",
    "# Generate output tensor targets for filtered bounding boxes.\n",
    "# TODO: Wrap these backend operations with Keras layers.\n",
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))\n",
    "input_image_shape = K.placeholder(shape=(2, ))\n",
    "boxes, scores, classes = yolo_eval(\n",
    "    yolo_outputs,\n",
    "    input_image_shape,\n",
    "    score_threshold = 0.3,\n",
    "    iou_threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 287, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('images/cars.jpg')\n",
    "# Resize image\n",
    "if model_image_size != (None, None):\n",
    "    # Fit to the fixed input shape\n",
    "    new_image_size = tuple(reversed(model_image_size))\n",
    "else:\n",
    "    # width and height as multiples of 32.\n",
    "    new_image_size = (image.width - (image.width % 32), image.height - (image.height % 32))\n",
    "\n",
    "resized_image = cv2.resize(image, new_image_size)\n",
    "\n",
    "# Convert to image to array\n",
    "image_data = resized_image.astype(np.float32)\n",
    "# Normalize image data\n",
    "image_data /= 255.\n",
    "# Add batch dimension\n",
    "image_data = np.expand_dims(image_data, 0)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'batch_normalization_1/keras_learning_phase:0' shape=() dtype=bool>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image_shape\n",
    "image.shape[0:2]\n",
    "yolo_model.input\n",
    "image_data.size\n",
    "K.learning_phase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 64.76033  , 150.21417  , 137.40349  , 252.67831  ],\n",
       "       [ 63.604656 ,  41.39669  , 136.65692  , 127.37525  ],\n",
       "       [ 49.14084  , 205.81718  ,  88.919655 , 281.43417  ],\n",
       "       [ 56.337082 ,   5.405297 ,  90.02035  ,  71.13803  ],\n",
       "       [ 48.45473  ,  99.249626 ,  63.380222 , 125.34176  ],\n",
       "       [ 45.13808  , 146.08812  ,  64.87708  , 173.07072  ],\n",
       "       [ 42.571827 , 235.09827  ,  56.19427  , 275.1776   ],\n",
       "       [ 44.19636  ,   6.6534643,  56.37396  ,  46.555763 ],\n",
       "       [ 44.65138  , 178.2846   ,  57.526653 , 211.23012  ],\n",
       "       [ 46.101936 ,  69.079765 ,  56.36043  ,  92.40315  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_boxes, out_scores, out_classes = sess.run([boxes, scores, classes],\n",
    "                                              feed_dict={yolo_model.input: image_data,\n",
    "                                                         input_image_shape: image.shape[0:2],\n",
    "                                                         K.learning_phase(): 0 })\n",
    "\n",
    "out_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in list(enumerate(classes)):\n",
    "    predicted_class = detector.class_names[c]\n",
    "    print({'index': i, 'label': predicted_class, 'score': scores[i], 'box': boxes[i]})\n",
    "    print(predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
